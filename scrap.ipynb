{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the OpenAI API client\n",
    "api_key =  # Replace with your actual OpenAI API key\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Goal(BaseModel):\n",
    "    description: str\n",
    "\n",
    "\n",
    "class Goals(BaseModel):\n",
    "    low_priority: list[Goal]\n",
    "    medium_priority: list[Goal]\n",
    "    high_priority: list[Goal]\n",
    "\n",
    "\n",
    "gpt_sys_prompt = \"\\nYou are a data science master's student from Tampa, FL who just completed their 2-year program at the University of Pennsylvania in Philadelphia, PA. You are currently working on an extension of your capstone project, which is to develop a new AI agent that can play the board game Survivor.\"\n",
    "\n",
    "gpt_user_prompt = \"\\nUsing the context above that describes the world and yourself, create high level goals at several priority levels for the next few months of your life. Make no more than 10 goals in total. Keep the goals concise.\"\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": gpt_sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": gpt_user_prompt},\n",
    "    ],\n",
    "    response_format=Goals,\n",
    ")\n",
    "\n",
    "goals = completion.choices[0].message\n",
    "\n",
    "# If the model refuses to respond, you will get a refusal message\n",
    "if goals.refusal:\n",
    "    print(goals.refusal)\n",
    "else:\n",
    "    print(goals.parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_dict = goals.parsed.model_dump()  # Directly access the parsed dictionary\n",
    "goals_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(goals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[goal.description for goal in goals.parsed.low_priority]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[goal.description for goal in goals.parsed.medium_priority]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[goal.description for goal in goals.parsed.high_priority]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"company\"\n",
    "text2 = \"corporation\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id = 0\n",
    "low_priority_goals = {\n",
    "    node_id + i: goal.description for i, goal in enumerate(goals.parsed.low_priority)\n",
    "}\n",
    "node_id += len(goals.parsed.low_priority)\n",
    "\n",
    "medium_priority_goals = {\n",
    "    node_id + i: goal.description for i, goal in enumerate(goals.parsed.medium_priority)\n",
    "}\n",
    "node_id += len(goals.parsed.medium_priority)\n",
    "\n",
    "high_priority_goals = {\n",
    "    node_id + i: goal.description for i, goal in enumerate(goals.parsed.high_priority)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_priority_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_priority_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_user_prompt = (\n",
    "    \"Your Goals are as follows:\\n\"\n",
    "    \"Low Priority:\\n\\t\"\n",
    "    + \"\\n\\t\".join(\n",
    "        [f\"Node ID: {key}, Goal: {value}\" for key, value in low_priority_goals.items()]\n",
    "    )\n",
    "    + \"\\n\\n\"\n",
    "    \"Medium Priority:\\n\\t\"\n",
    "    + \"\\n\\t\".join(\n",
    "        [\n",
    "            f\"Node ID: {key}, Goal: {value}\"\n",
    "            for key, value in medium_priority_goals.items()\n",
    "        ]\n",
    "    )\n",
    "    + \"\\n\\n\"\n",
    "    \"High Priority:\\n\\t\"\n",
    "    + \"\\n\\t\".join(\n",
    "        [f\"Node ID: {key}, Goal: {value}\" for key, value in high_priority_goals.items()]\n",
    "    )\n",
    "    + \"\\n\\n\"\n",
    "    \"Using the context above that describes the world and yourself, assign to each of the goals a progress score between 0 and 10 based on how important it is that you make progress on the goal. The scores should be in order of priority, with the highest priority goals having the highest scores.\"\n",
    ")\n",
    "\n",
    "print(gpt_user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score(BaseModel):\n",
    "    node_id: int\n",
    "    progress_score: int\n",
    "\n",
    "\n",
    "class Scores(BaseModel):\n",
    "    scores: list[Score]\n",
    "\n",
    "\n",
    "gpt_sys_prompt = \"\\nYou are a data science master's student from Tampa, FL who just completed their 2-year program at the University of Pennsylvania in Philadelphia, PA. You are currently working on an extension of your capstone project, which is to develop a new AI agent that can play the board game Survivor.\"\n",
    "\n",
    "gpt_user_prompt = (\n",
    "    \"Your Goals are as follows:\\n\"\n",
    "    \"Low Priority:\\n\\t\"\n",
    "    + \"\\n\\t\".join(\n",
    "        [f\"Node ID: {key}, Goal: {value}\" for key, value in low_priority_goals.items()]\n",
    "    )\n",
    "    + \"\\n\\n\"\n",
    "    \"Medium Priority:\\n\\t\"\n",
    "    + \"\\n\\t\".join(\n",
    "        [\n",
    "            f\"Node ID: {key}, Goal: {value}\"\n",
    "            for key, value in medium_priority_goals.items()\n",
    "        ]\n",
    "    )\n",
    "    + \"\\n\\n\"\n",
    "    \"High Priority:\\n\\t\"\n",
    "    + \"\\n\\t\".join(\n",
    "        [f\"Node ID: {key}, Goal: {value}\" for key, value in high_priority_goals.items()]\n",
    "    )\n",
    "    + \"\\n\\n\"\n",
    "    \"Using the context above that describes the world and yourself, assign to each of the goals a progress score between 0 and 10 based on how important it is that you make progress on the goal. The scores should be in order of priority, with the highest priority goals having the highest scores.\"\n",
    ")\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": gpt_sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": gpt_user_prompt},\n",
    "    ],\n",
    "    response_format=Scores,\n",
    ")\n",
    "\n",
    "scores = completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{score.node_id: score.progress_score for score in scores.scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dill\n",
    "%pip install torch\n",
    "%pip install bert\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import RobertaTokenizer, RobertaModel\n",
    "# from torch.nn.functional import cosine_similarity\n",
    "# import torch\n",
    "# import logging\n",
    "\n",
    "\n",
    "# # Set logging level for transformers to ERROR to suppress warnings\n",
    "# logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# def cosine_similarity_contextual_embeddings(text1, word1, text2, word2, mode=\"average\"):\n",
    "#     \"\"\"\n",
    "#     Compute the cosine similarity between the contextual embeddings of two words in their respective texts.\n",
    "\n",
    "#     Parameters:\n",
    "#     - text1: First piece of text\n",
    "#     - word1: Target word in the first text\n",
    "#     - text2: Second piece of text\n",
    "#     - word2: Target word in the second text\n",
    "#     - mode: 'average' or 'each'.\n",
    "#             'average' averages the embeddings for all occurrences of the word.\n",
    "#             'each' returns cosine similarity for each occurrence of the word separately.\n",
    "\n",
    "#     Returns:\n",
    "#     - Cosine similarity (averaged or per instance) between the contextualized embeddings of the two words.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Initialize the RoBERTa tokenizer and model\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "#     model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "#     def get_word_embeddings(text, word):\n",
    "#         # Tokenize the input text\n",
    "#         inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "#         tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "#         # Tokenize the target word\n",
    "#         word_tokens = tokenizer.tokenize(word)\n",
    "#         if word_tokens[0][0] != \"Ġ\":\n",
    "#             # Add the 'Ġ' if not present, since RoBERTa uses it to indicate a space before the word\n",
    "#             word_tokens = [\"Ġ\" + word_tokens[0]] + word_tokens[1:]\n",
    "\n",
    "#         # Get RoBERTa embeddings for the entire text\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "#             last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "#         # Find positions of the word in the tokenized input by matching subword tokens\n",
    "#         word_positions = []\n",
    "#         for i in range(len(tokenized_text) - len(word_tokens) + 1):\n",
    "#             # Check if the sequence of tokens in the text matches the word's token sequence\n",
    "#             if tokenized_text[i : i + len(word_tokens)] == word_tokens:\n",
    "#                 word_positions.append(i)  # Start index of the matched subwords\n",
    "\n",
    "#         if not word_positions:\n",
    "#             raise ValueError(\n",
    "#                 f\"Word '{word}' not found in the input text. Tokenized text: {tokenized_text}\"\n",
    "#             )\n",
    "\n",
    "#         # Get embeddings for each occurrence of the word by averaging subword embeddings\n",
    "#         word_embeddings = []\n",
    "#         for pos in word_positions:\n",
    "#             # Get embeddings for all subword tokens of the word\n",
    "#             subword_embeddings = last_hidden_state[:, pos : pos + len(word_tokens), :]\n",
    "#             word_embedding = subword_embeddings.mean(\n",
    "#                 dim=1\n",
    "#             )  # Average subword embeddings\n",
    "#             word_embeddings.append(word_embedding)\n",
    "\n",
    "#         word_embeddings = torch.stack(word_embeddings, dim=0)\n",
    "#         return word_embeddings\n",
    "\n",
    "#     # Get embeddings for both words in their respective contexts\n",
    "#     embeddings1 = get_word_embeddings(text1, word1)\n",
    "#     embeddings2 = get_word_embeddings(text2, word2)\n",
    "\n",
    "#     if mode == \"average\":\n",
    "#         # Average all occurrences\n",
    "#         embedding1 = embeddings1.mean(dim=0)\n",
    "#         embedding2 = embeddings2.mean(dim=0)\n",
    "#         # Compute cosine similarity between the averaged embeddings\n",
    "#         similarity = cosine_similarity(embedding1, embedding2)\n",
    "#         return similarity.item()\n",
    "\n",
    "#     elif mode == \"each\":\n",
    "#         # Compute cosine similarity for each occurrence of word1 with each occurrence of word2\n",
    "#         similarities = []\n",
    "#         for emb1 in embeddings1:  # Get individual embeddings of word1\n",
    "#             for emb2 in embeddings2:  # Get individual embeddings of word2\n",
    "#                 similarity = cosine_similarity(emb1, emb2)\n",
    "#                 similarities.append(similarity.item())\n",
    "#         return similarities\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid mode. Choose 'average' or 'each'.\")\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# text1 = \"The bank of the river was peaceful, but he also visited the bank to withdraw money.\"\n",
    "# word1 = \"bank\"\n",
    "\n",
    "# text2 = \"He stood at the riverbank and watched the water flow gently by.\"\n",
    "# word2 = \"riverbank\"\n",
    "\n",
    "# # Averaged cosine similarity\n",
    "# similarity_score = cosine_similarity_contextual_embeddings(\n",
    "#     text1, word1, text2, word2, mode=\"average\"\n",
    "# )\n",
    "# print(f\"Averaged cosine similarity between '{word1}' and '{word2}': {similarity_score}\")\n",
    "\n",
    "# # Cosine similarity for each occurrence\n",
    "# similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "#     text1, word1, text2, word2, mode=\"each\"\n",
    "# )\n",
    "# print(\n",
    "#     f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "\n",
    "def cosine_similarity_contextual_embeddings(text1, word1, text2, word2, mode=\"average\"):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between the contextual embeddings of two words in their respective texts.\n",
    "\n",
    "    Parameters:\n",
    "    - text1: First piece of text\n",
    "    - word1: Target word in the first text\n",
    "    - text2: Second piece of text\n",
    "    - word2: Target word in the second text\n",
    "    - mode: 'average' or 'each'.\n",
    "            'average' averages the embeddings for all occurrences of the word.\n",
    "            'each' returns cosine similarity for each occurrence of the word separately.\n",
    "\n",
    "    Returns:\n",
    "    - Cosine similarity (averaged or per instance) between the contextualized embeddings of the two words.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the BERT tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    def get_word_embeddings(text, word):\n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "\n",
    "        # Get input_ids for the target word\n",
    "        word_token_ids = tokenizer.convert_tokens_to_ids(word_tokens)\n",
    "\n",
    "        # Get BERT embeddings for the entire text\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            last_hidden_state = outputs.last_hidden_state[0]  # Remove batch dimension\n",
    "\n",
    "        # Find positions of the word in the tokenized input\n",
    "        word_positions = [\n",
    "            i\n",
    "            for i, token_id in enumerate(inputs[\"input_ids\"][0])\n",
    "            if token_id in word_token_ids\n",
    "        ]\n",
    "\n",
    "        # Get embeddings for each occurrence of the word\n",
    "        word_embeddings = last_hidden_state[word_positions, :]\n",
    "\n",
    "        return word_embeddings\n",
    "\n",
    "    # Get embeddings for both words in their respective contexts\n",
    "    embeddings1 = get_word_embeddings(text1, word1)\n",
    "    embeddings2 = get_word_embeddings(text2, word2)\n",
    "\n",
    "    if mode == \"average\":\n",
    "        # Average all occurrences\n",
    "        embedding1 = embeddings1.mean(dim=0)\n",
    "        embedding2 = embeddings2.mean(dim=0)\n",
    "        # Compute cosine similarity between the averaged embeddings\n",
    "        similarity = cosine_similarity(embedding1.unsqueeze(0), embedding2.unsqueeze(0))\n",
    "        return similarity.item()\n",
    "\n",
    "    elif mode == \"each\":\n",
    "        # Compute cosine similarity for each occurrence of word1 with each occurrence of word2\n",
    "        similarities = []\n",
    "        for emb1 in embeddings1:  # Get individual embeddings of word1\n",
    "            for emb2 in embeddings2:  # Get individual embeddings of word2\n",
    "                similarity = cosine_similarity(emb1.unsqueeze(0), emb2.unsqueeze(0))\n",
    "                similarities.append(similarity.item())\n",
    "        return similarities\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose 'average' or 'each'.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text1 = \"The bank of the river was peaceful, but he also visited the bank to withdraw money.\"\n",
    "word1 = \"bank\"\n",
    "\n",
    "text2 = \"He stood at the riverbank and watched the water flow gently by.\"\n",
    "word2 = \"riverbank\"\n",
    "\n",
    "# Averaged cosine similarity\n",
    "similarity_score = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"average\"\n",
    ")\n",
    "print(f\"Averaged cosine similarity between '{word1}' and '{word2}': {similarity_score}\")\n",
    "\n",
    "# Cosine similarity for each occurrence\n",
    "similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"each\"\n",
    ")\n",
    "print(\n",
    "    f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text1 = \"The corporation is a large company that makes money.\"\n",
    "word1 = \"corporation\"\n",
    "\n",
    "text2 = \"The company has seen year-over-year and quarter-over-quarter growth since its inception.\"\n",
    "word2 = \"company\"\n",
    "\n",
    "# Cosine similarity for each occurrence\n",
    "similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"each\"\n",
    ")\n",
    "print(\n",
    "    f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text1 = \"cat\"\n",
    "word1 = \"cat\"\n",
    "\n",
    "text2 = \"kitten\"\n",
    "word2 = \"kitten\"\n",
    "\n",
    "# Cosine similarity for each occurrence\n",
    "similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"each\"\n",
    ")\n",
    "print(\n",
    "    f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text1 = \"The cat is a small animal.\"\n",
    "word1 = \"cat\"\n",
    "\n",
    "text2 = \"The kitten is a small animal.\"\n",
    "word2 = \"kitten\"\n",
    "\n",
    "# Cosine similarity for each occurrence\n",
    "similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"each\"\n",
    ")\n",
    "print(\n",
    "    f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text1 = \"The cat played with the ball.\"\n",
    "word1 = \"cat\"\n",
    "\n",
    "text2 = \"The kitten is a small animal.\"\n",
    "word2 = \"kitten\"\n",
    "\n",
    "# Cosine similarity for each occurrence\n",
    "similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"each\"\n",
    ")\n",
    "print(\n",
    "    f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text1 = \"The baby went to the park.\"\n",
    "word1 = \"baby\"\n",
    "\n",
    "text2 = \"The kitten is stretching on the rug.\"\n",
    "word2 = \"kitten\"\n",
    "\n",
    "# Cosine similarity for each occurrence\n",
    "similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"each\"\n",
    ")\n",
    "print(\n",
    "    f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text1 = \"baby\"\n",
    "word1 = \"baby\"\n",
    "\n",
    "text2 = \"kitten\"\n",
    "word2 = \"kitten\"\n",
    "\n",
    "# Cosine similarity for each occurrence\n",
    "similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"each\"\n",
    ")\n",
    "print(\n",
    "    f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text1 = \"corporation\"\n",
    "word1 = \"corporation\"\n",
    "\n",
    "text2 = \"company\"\n",
    "word2 = \"company\"\n",
    "\n",
    "# Cosine similarity for each occurrence\n",
    "similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"each\"\n",
    ")\n",
    "print(\n",
    "    f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text1 = \"firm\"\n",
    "word1 = \"firm\"\n",
    "\n",
    "text2 = \"company\"\n",
    "word2 = \"company\"\n",
    "\n",
    "# Cosine similarity for each occurrence\n",
    "similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"each\"\n",
    ")\n",
    "print(\n",
    "    f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text1 = \"corporation\"\n",
    "word1 = \"corporation\"\n",
    "\n",
    "text2 = \"firm\"\n",
    "word2 = \"firm\"\n",
    "\n",
    "# Cosine similarity for each occurrence\n",
    "similarity_scores_each = cosine_similarity_contextual_embeddings(\n",
    "    text1, word1, text2, word2, mode=\"each\"\n",
    ")\n",
    "print(\n",
    "    f\"Cosine similarity between '{word1}' and '{word2}' for each occurrence: {similarity_scores_each}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the OpenAI API client\n",
    "api_key = None  # Replace with your actual OpenAI API key\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "# def compare_texts(text1, text2):\n",
    "# \"\"\"Compare two pieces of text and return their cosine similarity score.\"\"\"\n",
    "# embeddings = get_embeddings([text1, text2])\n",
    "# return cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"baby\"\n",
    "text2 = \"kitten\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"cat\"\n",
    "text2 = \"kitten\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"mouse\"\n",
    "text2 = \"mice\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"cat\"\n",
    "text2 = \"dog\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"company\"\n",
    "text2 = \"zoo\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"The cat is a small animal.\"\n",
    "text2 = \"The kitten is a small animal.\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"company\"\n",
    "text2 = \"corporation\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"firm\"\n",
    "text2 = \"corporation\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"firm\"\n",
    "text2 = \"company\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"The corporation is a large company that makes money.\"\n",
    "text2 = \"The company has seen year-over-year and quarter-over-quarter growth since its inception.\"\n",
    "\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"business\"\n",
    "text2 = \"company\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text1 = \"business\"\n",
    "text2 = \"company\"\n",
    "text1_embedding = get_embedding(text1)\n",
    "text2_embedding = get_embedding(text2)\n",
    "\n",
    "similarity_score = cosine_similarity(\n",
    "    torch.tensor(text1_embedding).unsqueeze(0),\n",
    "    torch.tensor(text2_embedding).unsqueeze(0),\n",
    ")\n",
    "print(f\"Cosine Similarity Score: {similarity_score.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
